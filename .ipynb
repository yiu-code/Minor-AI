{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from pycocotools.coco import COCO\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables import Keypoint, KeypointsOnImage\n",
    "\n",
    "class Process(object):\n",
    "    numKeypoint = 17\n",
    "    keypointsName = ['nose', 'left_eye', 'right_eye', 'left_ear', 'right_ear', \n",
    "                    'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow', \n",
    "                    'left_wrist', 'right_wrist', 'left_hip', 'right_hip', 'left_knee', \n",
    "                    'right_knee', 'left_ankle', 'right_ankle']\n",
    "\n",
    "    skeleton = [[15, 13], [13, 11], [16, 14], \n",
    "                [14, 12], [11, 12], [5, 11], \n",
    "                [6, 12], [5, 6], [5, 7], [6, 8], \n",
    "                [7, 9], [8, 10], [1, 2], [0, 1], \n",
    "                [0, 2], [1, 3], [2, 4], [3, 5], [4, 6]]\n",
    "    \n",
    "    trainAnnoPath = 'COCO/annotations/person_keypoints_train2017.json'\n",
    "    valAnnoPath = 'COCO/annotations/person_keypoints_val2017.json'\n",
    "    \n",
    "    augmentation = iaa.Resize(256)\n",
    "    \n",
    "\n",
    "    def loadData(self, setType):\n",
    "        if setType == 'train':\n",
    "            coco = COCO(self.trainAnnoPath)\n",
    "        elif setType == 'val':\n",
    "            coco = COCO(self.valAnnoPath)\n",
    "            \n",
    "        Data = []\n",
    "        for aid in coco.anns.keys():\n",
    "            ann =  coco.anns[aid]\n",
    "            keypoints = ann['keypoints']\n",
    "            \n",
    "            if  keypoints.count(0) == 0: \n",
    "                imageName = 'COCO/' + setType + '2017/' + coco.imgs[ann['image_id']]['file_name']\n",
    "\n",
    "                if (ann['image_id'] not in coco.imgs) or ann['iscrowd'] or (np.sum(keypoints[2::3]) == 0) or (ann['num_keypoints'] == 0):\n",
    "                    continue\n",
    "\n",
    "                data = dict(image_id = ann['image_id'], imgpath = imageName, bbox=ann['bbox'], keypoints=keypoints)\n",
    "                Data.append(data)\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "        return Data\n",
    "    \n",
    "    def imagesToNdarry(self, data): \n",
    "        imgPath = []\n",
    "        i = 0\n",
    "        for i in range(len(data)):\n",
    "            img = cv2.imread(data[i]['imgpath'])\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            imgPath.append(img)\n",
    "            \n",
    "        return np.array(imgPath)\n",
    "    \n",
    "    def splitKeypoints(self, data):\n",
    "        kpsList = []\n",
    "        visibiltyList = []\n",
    "        for ann in data:\n",
    "            keypoints = np.array(ann['keypoints']).astype(int)\n",
    "            keypoints =  keypoints.reshape(17,3)\n",
    "            \n",
    "            keypoints = self.reshapeKeypoints(keypoints)\n",
    "            kpsList.append(keypoints['kps'])\n",
    "            visibiltyList.append(keypoints['visibility'])\n",
    "\n",
    "        return kpsList, visibiltyList\n",
    "    \n",
    "    \n",
    "    def reshapeKeypoints(self, keypoints):\n",
    "        keypoint = []\n",
    "        visibility = []\n",
    "\n",
    "        for kps in keypoints: \n",
    "            x,y,v = kps \n",
    "            keypoint.append(Keypoint(x,y))\n",
    "            visibility.append(v)\n",
    "            \n",
    "        res = dict()\n",
    "        res['kps'] = keypoint; res['visibility'] = visibility\n",
    "        return res\n",
    "    \n",
    "    def augmentKeypoints(self, keypoints, shape):\n",
    "        augKpsList = []\n",
    "        for kps in keypoints:\n",
    "            augKps = self.augmentation.augment_keypoints(KeypointsOnImage(kps, shape))\n",
    "            augKpsList.append(augKps)\n",
    "        return augKpsList\n",
    "    \n",
    "    def mergeKpsVisibility(self, augKps, visibility, kpShape, MergeShape):\n",
    "        kpsList = [] \n",
    "        i = 0\n",
    "        for i in range(len(augKps)):\n",
    "            for keypoint in augKps[i]:\n",
    "                x,y = keypoint.x, keypoint.y\n",
    "                kpsList.append(x)\n",
    "                kpsList.append(y)\n",
    "        kpsList = np.array(kpsList).reshape(kpShape)\n",
    "        merge = np.dstack((kpsList, visibility))\n",
    "        merge = merge.reshape(MergeShape)\n",
    "        return merge\n",
    "    \n",
    "    def augmentationOnAll(self, images, kps):\n",
    "        seq = iaa.Sequential([\n",
    "            iaa.Resize(112),            \n",
    "        ])\n",
    "\n",
    "        imgAugList = []\n",
    "        kpsAugList = []\n",
    "        \n",
    "        i = 0 \n",
    "        for i in range(len(images)):\n",
    "            imgAug, kpsAug = seq(image=images[i], keypoints=KeypointsOnImage(kps[i],shape=images[i].shape))\n",
    "            imgAugList.append(imgAug)\n",
    "            kpsAugList.append(kpsAug)\n",
    "            \n",
    "        return np.array(imgAugList), kpsAugList\n",
    "    \n",
    "    def formatToDataframe(self, anno ,keypoints):\n",
    "        col_name  = ['nose_x', 'nose_y', 'nose_v',\n",
    "                     'left_eye_x','left_eye_y', 'left_eye_v', \n",
    "                     'right_eye_x', 'right_eye_y', 'right_eye_v',\n",
    "                     'left_ear_x', 'left_ear_y', 'left_ear_v',\n",
    "                     'right_ear_x', 'right_ear_y', 'right_ear_v',\n",
    "                    'left_shoulder_x', 'left_shoulder_y', 'left_shoulder_v',\n",
    "                     'right_shoulder_x', 'right_shoulder_y', 'right_shoulder_v',\n",
    "                     'left_elbow_x', 'left_elbow_y', 'left_elbow_v',\n",
    "                     'right_elbow_x', 'right_elbow_y', 'right_elbow_v', \n",
    "                    'left_wrist_x', 'left_wrist_y', 'left_wrist_v',\n",
    "                     'right_wrist_x', 'right_wrist_y', 'right_wrist_v',\n",
    "                     'left_hip_x', 'left_hip_y', 'left_hip_v', \n",
    "                     'right_hip_x', 'right_hip_y', 'right_hip_v',\n",
    "                     'left_knee_x', 'left_knee_y', 'left_knee_v',\n",
    "                    'right_knee_x', 'right_knee_y', 'right_knee_v', \n",
    "                     'left_ankle_x', 'left_ankle_y', 'left_ankle_v', \n",
    "                     'right_ankle_x', 'right_ankle_y', 'right_ankle_v',\n",
    "                     'image_path'  \n",
    "                    ]\n",
    "        data = []\n",
    "\n",
    "        i = 0\n",
    "        for ann, kps in zip(anno, keypoints):\n",
    "            cur_row = []\n",
    "#                 bbox = np.array(anno[i]['bbox']).astype(int)\n",
    "#             keypoints = np.array(anno[i]['keypoints']).astype(int)\n",
    "#                 for loc in bbox:\n",
    "#                     cur_row.append(loc)\n",
    "            for key in kps:\n",
    "                cur_row.append(int(key))\n",
    "            cur_row.append(anno[i]['imgpath'])\n",
    "            data.append(cur_row)\n",
    "\n",
    "        return pd.DataFrame(data=data, columns=col_name)\n",
    "\n",
    "\n",
    "processing = Process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Setup(object):\n",
    "    setType = ''\n",
    "    batchsize = 0\n",
    "    fetchedData = []\n",
    "    \n",
    "    def __init__ (self, setType, batchSize):\n",
    "        self.setType = setType\n",
    "        self.batchsize = batchSize\n",
    "        \n",
    "    def getTrainingSet(self):\n",
    "        batch = processing.loadData('train')\n",
    "        batch = batch[:self.batchsize]\n",
    "        \n",
    "        images = processing.imagesToNdarry(batch)\n",
    "        \n",
    "        kpsList, visibilityList = processing.splitKeypoints(batch)\n",
    "        \n",
    "        x, kps = processing.augmentationOnAll(images, kpsList)\n",
    "        Y = processing.mergeKpsVisibility(kps, visibilityList, (self.batchsize, 17,2), (self.batchsize, 51))\n",
    "        images = [] \n",
    "        return x, Y, batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=10.31s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "setup = Setup('train', 8000)\n",
    "x , Y, batch = setup.getTrainingSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in Y: \n",
    "#     for j in i:\n",
    "#         print(j)\n",
    "#         print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_id': 528962, 'imgpath': 'COCO/train2017/000000528962.jpg', 'bbox': [369.94, 98.6, 69.95, 208.14], 'keypoints': [407, 124, 2, 410, 117, 2, 402, 119, 2, 419, 119, 2, 399, 122, 2, 427, 143, 2, 388, 143, 2, 433, 168, 2, 378, 170, 2, 431, 183, 2, 380, 187, 2, 416, 195, 2, 392, 194, 2, 421, 245, 2, 385, 214, 2, 418, 289, 2, 391, 247, 2]}\n",
      "[91.16799927 37.03466797  2.         91.83999634 34.94400024  2.\n",
      " 90.04800415 35.54133606  2.         93.85600281 35.54133606  2.\n",
      " 89.37599945 36.43733215  2.         95.647995   42.70933151  2.\n",
      " 86.91200256 42.70933151  2.         96.99199677 50.1760025   2.\n",
      " 84.67199707 50.7733345   2.         96.54399872 54.65600204  2.\n",
      " 85.11999512 55.85066605  2.         93.18400574 58.23999786  2.\n",
      " 87.80799866 57.94133377  2.         94.30400085 73.17333221  2.\n",
      " 86.23999786 63.91466522  2.         93.63200378 86.31466675  2.\n",
      " 87.58399963 73.77066803  2.        ]\n"
     ]
    }
   ],
   "source": [
    "print(batch[0])\n",
    "print(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = processing.formatToDataframe(batch, Y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('augCOCO.csv',encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
