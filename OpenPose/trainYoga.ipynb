{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('OpenPose.json') as f:\n",
    "  file = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = file['data']\n",
    "x_train =[]\n",
    "y_train = []\n",
    "\n",
    "def labelToNumerical(label):\n",
    "    if label == 'WarriorPoseI':\n",
    "        return 0\n",
    "    if label == 'WarriorPoseII':\n",
    "        return 1\n",
    "    if label == 'WarriorPoseIII':\n",
    "        return 2\n",
    "    if label == 'TreePose':\n",
    "        return 3\n",
    "\n",
    "i = 0\n",
    "for i in range(len(data)):\n",
    "    kpsArr = []\n",
    "    labels = []\n",
    "    for kps in data[i]['xs'].items():\n",
    "        print\n",
    "        kpsArr.append(kps[1])\n",
    "    for label in data[i]['ys'].items():\n",
    "        labels.append(labelToNumerical(label[1]))\n",
    "    x_train.append(kpsArr)\n",
    "    y_train.append(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 481.95, 640.0, 495.3375, 613.3333333333334, 508.725, 426.6666666666667, 428.4, 266.6666666666667, 468.5625, 666.6666666666666, 415.0125, 453.3333333333333, 334.6875, 293.3333333333333, 575.6625, 853.3333333333334, 307.9125, 1146.6666666666667, 200.8125, 1306.6666666666667, 589.05, 880.0, 696.15, 960.0, 736.3125, 1120.0, 0, 0, 0, 0, 455.175, 533.3333333333334, 388.2375, 613.3333333333334]\n",
      "(110, 36)\n",
      "[   0.            0.          481.95        640.          495.3375\n",
      "  613.33333333  508.725       426.66666667  428.4         266.66666667\n",
      "  468.5625      666.66666667  415.0125      453.33333333  334.6875\n",
      "  293.33333333  575.6625      853.33333333  307.9125     1146.66666667\n",
      "  200.8125     1306.66666667  589.05        880.          696.15\n",
      "  960.          736.3125     1120.            0.            0.\n",
      "    0.            0.          455.175       533.33333333  388.2375\n",
      "  613.33333333]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "x_train = np.asarray(x_train)\n",
    "print(x_train.shape)\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "(152, 1)\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "y_train = np.asarray(y_train)\n",
    "print(y_train.shape)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat_train = to_categorical(y_train,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cat_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 121 samples, validate on 31 samples\n",
      "Epoch 1/100\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 366.6542 - accuracy: 0.0083 - val_loss: 249.9700 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 241.4447 - accuracy: 0.0413 - val_loss: 164.9237 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "121/121 [==============================] - 0s 58us/step - loss: 182.3717 - accuracy: 0.0579 - val_loss: 86.7679 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 107.1335 - accuracy: 0.2810 - val_loss: 36.9450 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 75.4896 - accuracy: 0.3719 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 54.8550 - accuracy: 0.5207 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 32.7502 - accuracy: 0.5702 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 31.0753 - accuracy: 0.5207 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 18.3033 - accuracy: 0.6116 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 9.4304 - accuracy: 0.6281 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 3.7385 - accuracy: 0.7769 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "121/121 [==============================] - 0s 58us/step - loss: 0.7494 - accuracy: 0.8678 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.6248 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.5790 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.6209 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.6081 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.7470 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.6584 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.6671 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.6113 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.7056 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.6180 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.6055 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.6036 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.6967 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.6628 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.6187 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.6585 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.6355 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.6748 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.6415 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.7218 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.6371 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.5937 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.6020 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.5999 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.5776 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.5959 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.5435 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.5819 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "121/121 [==============================] - 0s 0us/step - loss: 0.6099 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "121/121 [==============================] - 0s 123us/step - loss: 0.6576 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "121/121 [==============================] - 0s 33us/step - loss: 0.5858 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.6332 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.6014 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.5796 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.6460 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.5169 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.5637 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.6681 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.5499 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.5095 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.6514 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.6299 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.5705 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.5967 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.5944 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.5453 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.5525 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.6250 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.6598 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.6110 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.5900 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.5417 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.4939 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.5558 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.5265 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.5245 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.5676 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.5475 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "121/121 [==============================] - 0s 44us/step - loss: 0.5454 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.5076 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.5501 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.5392 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.4755 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.5965 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.4719 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.5570 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.5462 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.4837 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.4990 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.5827 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.5122 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.5781 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.4318 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "121/121 [==============================] - 0s 58us/step - loss: 0.5060 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.4790 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.4102 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.5504 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.5152 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.5048 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.5111 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.4844 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.3680 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.6111 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.5193 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.4930 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.4830 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "121/121 [==============================] - 0s 50us/step - loss: 0.4969 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "121/121 [==============================] - 0s 41us/step - loss: 0.5030 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(x_train, y_cat_train, validation_split=0.2, verbose=1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x205ca4603c8>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAbN0lEQVR4nO3dfZBV9Z3n8ffn3u7b0E0jNDTaAgbC4hg0BjMt68PEzcZkNM7sYmbXKdxJiq11l/xhasxWqqY088cmNUXt7FYedncqppaoGyqT0aISM1JuNhuHJGMyyUrQIUREQhsUEJRWQBGw6e773T/Ouc2laehLd18u95zPq6T63nPPw/d3Hz73+Lvn/I4iAjMzy5ZCowswM7Op53A3M8sgh7uZWQY53M3MMsjhbmaWQS2NLgBg7ty5sWjRokaXYWbWVJ599tk3IqJ7rMcuinBftGgRW7ZsaXQZZmZNRdIrZ3vM3TJmZhnkcDczyyCHu5lZBjnczcwyyOFuZpZBDnczswxyuJuZZVBTh/v+Iyf4yg93svuNY40uxczsotLU4X7o2En+x4/66Dv4TqNLMTO7qDR1uE8vFQE4fnKowZWYmV1cmjrcO0rJ6AnHTw43uBIzs4tLU4d7e1uy535swHvuZmbVmjvcW5NwP+E9dzOz0zR1uLcUC5RaChxzuJuZnWbccJc0TdJmSb+StF3SF9PpX5D0qqSt6b87qpZ5QFKfpJ2SbqtnAzpKRf+gamY2Si3juQ8AH4mIdyS1Aj+T9H/Sx74aEV+qnlnSMmAVcDVwOfB3kq6MiLrsXreXWvyDqpnZKOPuuUeiciB5a/ovzrHISuCxiBiIiN1AH7Bi0pWeRbv33M3MzlBTn7ukoqStwEHgqYh4Jn3oM5K2SXpE0ux02nxgb9Xi+9Jpo9e5RtIWSVv6+/sn3ID2UpFjA95zNzOrVlO4R8RwRCwHFgArJF0DfB1YAiwHDgBfTmfXWKsYY53rIqI3Inq7u8e8BGBN2kstPlrGzGyU8zpaJiKOAD8Bbo+I19PQLwPf4FTXyz5gYdViC4D9U1DrmDraihxzt4yZ2WlqOVqmW9Ks9PZ04KPAi5J6qmb7BPB8ensjsEpSm6TFwFJg89SWfcp0/6BqZnaGWo6W6QHWSyqSfBlsiIgnJX1L0nKSLpeXgU8DRMR2SRuAF4Ah4N56HSkDPhTSzGws44Z7RGwDrhtj+qfOscxaYO3kSqtNe6mF4/5B1czsNE19hiqkR8ucHCLiXEdnmpnlS/OHe1uRcsDAULnRpZiZXTSaPtw97K+Z2ZmaPtwrF+zwsL9mZqc0fbhX9txPDHrP3cysounD3RfsMDM7U/OHe2vlOqreczczq2j6cO9o8w+qZmajNX24t5cqe+7uljEzq8hAuHvP3cxstOYPd/+gamZ2huYPd/+gamZ2hqYP95ZigVJLweFuZlal6cMdPOyvmdlomQj39lKLr6NqZlYlI+Fe5MSg99zNzCqyEe5t3nM3M6uWjXBvdZ+7mVm1Wi6QPU3SZkm/krRd0hfT6V2SnpK0K/07u2qZByT1Sdop6bZ6NgCgo63oo2XMzKrUsuc+AHwkIj4ALAdul3QDcD+wKSKWApvS+0haBqwCrgZuBx5ML65dN+2lFoe7mVmVccM9Eu+kd1vTfwGsBNan09cDd6a3VwKPRcRAROwG+oAVU1r1KO2los9QNTOrUlOfu6SipK3AQeCpiHgGuDQiDgCkf+els88H9lYtvi+dNnqdayRtkbSlv79/Mm2gvdTCCe+5m5mNqCncI2I4IpYDC4AVkq45x+waaxVjrHNdRPRGRG93d3dt1Z5FR1uRYyeHiDhjM2ZmuXReR8tExBHgJyR96a9L6gFI/x5MZ9sHLKxabAGwf9KVnsP0UpFywMBQuZ6bMTNrGrUcLdMtaVZ6ezrwUeBFYCOwOp1tNfBEensjsEpSm6TFwFJg81QXXq3Dw/6amZ2mpYZ5eoD16REvBWBDRDwp6RfABkn3AHuAuwAiYrukDcALwBBwb0TUNXUrF+w4NjBEV0epnpsyM2sK44Z7RGwDrhtj+pvArWdZZi2wdtLV1cgX7DAzO102zlBt86X2zMyqZSLc3eduZna6TIR7dZ+7mZllLNxPDHrP3cwMMhPuSbeMh/01M0tkI9z9g6qZ2WmyEe6tlXD3nruZGWQk3FuKBUotBY55z93MDMhIuAN0lIoeGdLMLJWZcG8v+TqqZmYVGQp3X0fVzKwiO+He5kvtmZlVZCbcO7znbmY2IjPhnlxH1XvuZmaQqXBv8fADZmapzIR7R1vRA4eZmaUyE+7TW/2DqplZRWbCvaMt+UE1IhpdiplZw9VygeyFkn4saYek7ZLuS6d/QdKrkram/+6oWuYBSX2Sdkq6rZ4NqGgvtVAOGBgqX4jNmZld1Gq5QPYQ8LmIeE5SJ/CspKfSx74aEV+qnlnSMmAVcDVwOfB3kq68kBfJnpYOJGZmllfj7rlHxIGIeC69fRTYAcw/xyIrgcciYiAidgN9wIqpKPZcKuHufnczs/Psc5e0CLgOeCad9BlJ2yQ9Iml2Om0+sLdqsX2M8WUgaY2kLZK29Pf3n3fho7X7OqpmZiNqDndJM4DvAp+NiLeBrwNLgOXAAeDLlVnHWPyMXzkjYl1E9EZEb3d393kXPlrlgh0e9tfMrMZwl9RKEuzfjojHASLi9YgYjogy8A1Odb3sAxZWLb4A2D91JY+tI91z97C/Zma1HS0j4GFgR0R8pWp6T9VsnwCeT29vBFZJapO0GFgKbJ66ksdW/YOqmVne1XK0zM3Ap4BfS9qaTvs8cLek5SRdLi8DnwaIiO2SNgAvkBxpc2+9j5SBqnB3t4yZ2fjhHhE/Y+x+9O+fY5m1wNpJ1HXeujpKABw6NnghN2tmdlHKzBmql0xvpVQscPDou40uxcys4TIT7pLo7myj/+hAo0sxM2u4zIQ74HA3M0tlLtwPvu1wNzPLVLjP62yj/x2Hu5lZxsJ9GoeOneSkR4Y0s5zLVrjPbAPgDe+9m1nOZSrcu2ck4e4fVc0s7zIV7pU994MOdzPLuWyFe+c0AJ/IZGa5l6lwnzOjhORuGTOzTIV7a7FAV3vJ3TJmlnuZCnfwiUxmZpDRcPeJTGaWd5kL93md0+h/2z+omlm+ZS/cZyZ77hFnXLbVzCw3Mhfu3TPaGBwOjhz3RTvMLL8yF+4+kcnMrLYLZC+U9GNJOyRtl3RfOr1L0lOSdqV/Z1ct84CkPkk7Jd1WzwaM5hOZzMxq23MfAj4XEe8DbgDulbQMuB/YFBFLgU3pfdLHVgFXA7cDD0oq1qP4sXR3enwZM7Nxwz0iDkTEc+nto8AOYD6wElifzrYeuDO9vRJ4LCIGImI30AesmOrCz2Zep7tlzMzOq89d0iLgOuAZ4NKIOADJFwAwL51tPrC3arF96bTR61ojaYukLf39/edf+Vl0tLXQUSr6RCYzy7Waw13SDOC7wGcj4u1zzTrGtDOOS4yIdRHRGxG93d3dtZZRE5/IZGZ5V1O4S2olCfZvR8Tj6eTXJfWkj/cAB9Pp+4CFVYsvAPZPTbm1mdc5jYM+kcnMcqyWo2UEPAzsiIivVD20EVid3l4NPFE1fZWkNkmLgaXA5qkreXzdM9v8g6qZ5VpLDfPcDHwK+LWkrem0zwN/CWyQdA+wB7gLICK2S9oAvEBypM29ETE85ZWfQ/eMNp52uJtZjo0b7hHxM8buRwe49SzLrAXWTqKuSZk3s42jA0OcODnM9NIFOwrTzOyikbkzVMEnMpmZZTLcfSKTmeVdJsPdJzKZWd5lO9x9OKSZ5VQmw31We3Kh7EMe9tfMciqT4V4siEumt3Lk+MlGl2Jm1hCZDHeA2e0lDnvP3cxyKsPh3srhY95zN7N8ynC4lzjsbhkzy6nshntHyXvuZpZb2Q339lb3uZtZbmU23Ge1lzgxOMy7gxd0zDIzs4tCZsO9q6ME4H53M8ulzIb77PZWAA4fc9eMmeVPZsN9Vrv33M0svzIb7u6WMbM8y2y4z6p0y/iIGTPLocyG++xKt4yPdTezHKrlAtmPSDoo6fmqaV+Q9Kqkrem/O6oee0BSn6Sdkm6rV+HjaS0W6GxrcbeMmeVSLXvu3wRuH2P6VyNiefrv+wCSlgGrgKvTZR6U1LCLmM7q8PgyZpZP44Z7RDwNHKpxfSuBxyJiICJ2A33AiknUNyldHhnSzHJqMn3un5G0Le22mZ1Omw/srZpnXzrtDJLWSNoiaUt/f/8kyji7We0lj+luZrk00XD/OrAEWA4cAL6cTtcY88ZYK4iIdRHRGxG93d3dEyzj3Lo6ShxyuJtZDk0o3CPi9YgYjogy8A1Odb3sAxZWzboA2D+5EiduVnsrR3yGqpnl0ITCXVJP1d1PAJUjaTYCqyS1SVoMLAU2T67EiZvdXuLowBAnh8qNKsHMrCFaxptB0qPAh4G5kvYB/wn4sKTlJF0uLwOfBoiI7ZI2AC8AQ8C9EdGwYRlnp2epHjlxknmd0xpVhpnZBTduuEfE3WNMfvgc868F1k6mqKlSGTzsyPFBh7uZ5Upmz1CFU2epHvKx7maWM7kIdx8OaWZ5k+1w70i6ZQ75iBkzy5lsh7vHdDeznMp0uE9rLTK9tehuGTPLnUyHOyRHzLhbxszyJvvh3uHxZcwsf7If7u0eX8bM8if74d5R4oiH/TWznMl+uLe3+mgZM8udzIf7rPYSb50YZLg85sjDZmaZlPlw72pvJQLeOuGuGTPLj8yHe2VkSI8vY2Z5kvlwn+XxZcwshzIf7l0jQxC4W8bM8iPz4T4rHdP9sLtlzCxHMh/uXR0ePMzM8ifz4d5eKtJeKnLgrXcbXYqZ2QUzbrhLekTSQUnPV03rkvSUpF3p39lVjz0gqU/STkm31avwWkniyks72fna0UaXYmZ2wdSy5/5N4PZR0+4HNkXEUmBTeh9Jy4BVwNXpMg9KKk5ZtRP0vp5OXnztbSJ8IpOZ5cO44R4RTwOHRk1eCaxPb68H7qya/lhEDETEbqAPWDFFtU7YVZfN5PDxQV5/e6DRpZiZXRAT7XO/NCIOAKR/56XT5wN7q+bbl047g6Q1krZI2tLf3z/BMmpz1WWdAOx47e26bsfM7GIx1T+oaoxpY/aFRMS6iOiNiN7u7u4pLuN0V102E4AXD7jf3czyYaLh/rqkHoD078F0+j5gYdV8C4D9Ey9valzS3srll0zjRe+5m1lOTDTcNwKr09urgSeqpq+S1CZpMbAU2Dy5EqfGVT0zveduZrlRy6GQjwK/AH5H0j5J9wB/CXxM0i7gY+l9ImI7sAF4AfgBcG9EDNer+PNx1WWdvNT/DgNDF0U5ZmZ11TLeDBFx91keuvUs868F1k6mqHq4qmcmQ+XgpYPHWHb5zEaXY2ZWV5k/Q7ViWU9yxIz73c0sD3IT7ovmdFBqKfCiz1Q1sxzITbi3FAtceekMdhzwnruZZV9uwh2S4929525meZCzcO+k/+gAb7zjYQjMLNtyFe7v6/GZqmaWD7kK98oYMz5ixsyyLlfhPmdGG5fNnMbWvUcaXYqZWV3lKtwBbvonc/iHvjcYLntsdzPLrtyF+y1Luzl8fJDnX32r0aWYmdVN7sL995bOBeCnu+o7hryZWSPlLtznzmjjmvkzefo3bzS6FDOzuslduAN8aGk3z+05zNF3BxtdiplZXeQy3G9Z2s1QOfjFS282uhQzs7rIZbj/7ntm01Eq8rT73c0so3IZ7qWWAjcumeN+dzPLrFyGOyT97nsOHeeVN481uhQzsymX23C/5cpuAJ7+jbtmzCx7JhXukl6W9GtJWyVtSad1SXpK0q707+ypKXVqLZrTzsKu6Ty9y10zZpY9U7Hn/s8jYnlE9Kb37wc2RcRSYFN6/6IjiZuXzOX//fZND0VgZplTj26ZlcD69PZ64M46bGNK3LhkDkffHWL7fg9FYGbZMtlwD+CHkp6VtCaddmlEHABI/84ba0FJayRtkbSlv78x/d43LpkD4OPdzSxzJhvuN0fEB4GPA/dKuqXWBSNiXUT0RkRvd3f3JMuYmHmd01g6bwY/d7ibWcZMKtwjYn/69yDwPWAF8LqkHoD078HJFllPNy2Zwy9fPsTJoXKjSzEzmzITDndJHZI6K7eB3weeBzYCq9PZVgNPTLbIerpxyVyOnxxm2z5fwMPMsqNlEsteCnxPUmU9fxMRP5D0S2CDpHuAPcBdky+zfm54bxcS/PylN+ld1NXocszMpsSEwz0ifgt8YIzpbwK3TqaoC2lWe4llPTP5+Utv8Ke3Lm10OWZmUyK3Z6hWu2nJHJ575QjvDg43uhQzsynhcAduWjKXk8Nlnn3lcKNLMTObEg534PrFXRQLYtOOg0T4bFUza36T+UE1M2a0tXDTkjk88g+7eXLbfj5y1Tw+ecN7uGb+JY0uzcxsQrznnvran3yQL931Aa5f1MX/3naATz38jPvgzaxpOdxTM6e18q9/dwFf+5MP8tDqXg4fH+Tx515tdFlmZhPicB/DisVdvH/+JTz0s99S9oiRZtaEHO5jkMS//9Biftt/jJ/85qIePcHMbEwO97O44/09XDZzGg/9dHejSzEzO28O97NoLRb4tzcv4ucvvenx3s2s6Tjcz+Hu66+gvVTkYe+9m1mTcbifwyXtrfybFVfwt1tfZetejxppZs3D4T6O+z66lHmd07j/u9s85ruZNQ2H+zg6p7XyF3dew4uvHeV//v1LjS7HzKwmDvcafGzZpfzBtT381Y/66Dv4TqPLMTMbl8O9Rl/4F1czvVTkz77zKw9LYGYXPYd7jbo721j7iWv4x71HWPOtZx3wZnZRc7ifhz+89nL+yx9dy0939TvgzeyiVrdwl3S7pJ2S+iTdX6/tXGh/fP3CkYD/d9/8Ja+8eazRJZmZnaEu4S6pCHwN+DiwDLhb0rJ6bKsR/vj6hfzXf3Utz+05zK1f/ns+/71f8+qREwwNl8/7Yh/D5eDdwWHeHRyueflyORguR83bikjmL5/HMrXUMDhcnlCbzaz+6nWxjhVAX3oRbSQ9BqwEXqjT9i64u3oX8s+u7OavftTHo5v38DfP7Bl5rLUoChISFCQioBzB6AgcGi4z3qCTlXUUJYJgqBxUZ2lLIdkWyX8jywCUI/nyGB61kco6CwKhkdrK6YoLEoKRaZXtVZarnlZREBQLQul6z9kmkuemso3Kugrp+qVkWvX2R56/9HY5ImlD4dRzUw5GvmhGtqFTt8sRlMswHEFRoqUoWosFigWljyXP1WA5ki8toLVQoKWo5HmuPNfA4FCZgfTLLXlu0uczfa2KBRFpzaOfq+rnv6Iy33A5GE5rqX5Nijr9dT61jmQ9ldqSdSbtqewASKeeb6X1V2orV7+fRs1TqVXpe6JST/VIqZV2V157IP3ST16j1mJh5PMwXE7ev+WR1+j05SvbIH0uypG8DsPlqtc6fV6Hy8nrXSyIUkuBUjHZT61sY3TtxYIoFJL1Dg6XOTmUrregkToqz+uY71gl78+WQtqegnj35DDH0x2zymveUixUrUcj66usdqz3w8eWXcp//qP3j7XhSalXuM8H9lbd3wf80+oZJK0B1gBcccUVdSqjvubNnMZf3HkN/+FD7+UH2w8wMFhmcLjMYPoGjkg+PIWCRkKmIghKxQKtxSQ8KvMOjk77SD7sw+XKm0sUC+kbOYLhcpnhcrK+dMWnKAmnUx+cqqAcCcnTQzXd5KnwrHrHRxqqxapQBRgqVz5syfrKEYz5GaHy5o6R8K7+QEUkbYo4FV6CkQ8gY3wpVYJQ0hltOBWuyTorAVgsJF98g0NlhsrBULlMUUk4JR9Q0VooIMHgcBIwQ2lQlqPy2hVpbUnmq7yelbYnXxKMBIJGJUakr2d51Ke8Ulvlua1uT/VzS+WLr1y1zVGvabHASJsqy4/1haxRz9kZr1fVdkee+6r2VD9eaU9r+r5W+t44OVymXA5aijqtpurlT72OyQstndpxOe3Ld6SOyhdGmZPDMXKCYeVLuPJuqzwnledbQKmlMPKlXv2aVtpfeV+e/p5Nah0cTt4vQ+VgWkuR9lKR6aUi5fRLZahcHnlvn3o+T72nEzrtS+TaOl3xrV7hPtZn+7S3TkSsA9YB9Pb2NvX/118xp501tyxpdBlmZiPq9YPqPmBh1f0FwP46bcvMzEapV7j/ElgqabGkErAK2FinbZmZ2Sh16ZaJiCFJnwH+L1AEHomI7fXYlpmZnalefe5ExPeB79dr/WZmdnY+Q9XMLIMc7mZmGeRwNzPLIIe7mVkG6WIYF0RSP/DKJFYxF3hjisppFnlsM+Sz3W5zfpxvu98TEd1jPXBRhPtkSdoSEb2NruNCymObIZ/tdpvzYyrb7W4ZM7MMcribmWVQVsJ9XaMLaIA8thny2W63OT+mrN2Z6HM3M7PTZWXP3czMqjjczcwyqKnDPasX4a4maaGkH0vaIWm7pPvS6V2SnpK0K/07u9G11oOkoqR/lPRkej/T7ZY0S9J3JL2YvuY3Zr3NAJL+Y/r+fl7So5KmZbHdkh6RdFDS81XTztpOSQ+k+bZT0m3ns62mDfesX4S7yhDwuYh4H3ADcG/azvuBTRGxFNiU3s+i+4AdVfez3u7/DvwgIq4CPkDS9ky3WdJ84E+B3oi4hmSY8FVks93fBG4fNW3Mdqaf81XA1ekyD6a5V5OmDXeqLsIdESeBykW4MyUiDkTEc+ntoyQf9vkkbV2fzrYeuLMxFdaPpAXAHwAPVU3ObLslzQRuAR4GiIiTEXGEDLe5SgswXVIL0E5y5bbMtTsingYOjZp8tnauBB6LiIGI2A30keReTZo53Me6CPf8BtVyQUhaBFwHPANcGhEHIPkCAOY1rrK6+W/AnwHlqmlZbvd7gX7gf6VdUQ9J6iDbbSYiXgW+BOwBDgBvRcQPyXi7q5ytnZPKuGYO93Evwp0lkmYA3wU+GxFvN7qeepP0h8DBiHi20bVcQC3AB4GvR8R1wDGy0RVxTmkf80pgMXA50CHpk42t6qIwqYxr5nDPzUW4JbWSBPu3I+LxdPLrknrSx3uAg42qr05uBv6lpJdJutw+IumvyXa79wH7IuKZ9P53SMI+y20G+CiwOyL6I2IQeBy4iey3u+Js7ZxUxjVzuOfiItySRNIHuyMivlL10EZgdXp7NfDEha6tniLigYhYEBGLSF7bH0XEJ8lwuyPiNWCvpN9JJ90KvECG25zaA9wgqT19v99K8ttS1ttdcbZ2bgRWSWqTtBhYCmyuea0R0bT/gDuA3wAvAX/e6Hrq1MbfI/lfsW3A1vTfHcAckl/Wd6V/uxpdax2fgw8DT6a3M91uYDmwJX29/xaYnfU2p+3+IvAi8DzwLaAti+0GHiX5XWGQZM/8nnO1E/jzNN92Ah8/n215+AEzswxq5m4ZMzM7C4e7mVkGOdzNzDLI4W5mlkEOdzOzDHK4m5llkMPdzCyD/j/6esYjsJHj4wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(hist.history['loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
