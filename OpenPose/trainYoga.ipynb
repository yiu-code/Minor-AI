{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('OpenPose.json') as f:\n",
    "  file = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = file['data']\n",
    "x_train =[]\n",
    "y_train = []\n",
    "\n",
    "def labelToNumerical(label):\n",
    "    if label == 'WarriorPoseI':\n",
    "        return 0\n",
    "    if label == 'WarriorPoseII':\n",
    "        return 1\n",
    "    if label == 'WarriorPoseIII':\n",
    "        return 2\n",
    "    if label == 'TreePose':\n",
    "        return 3\n",
    "\n",
    "i = 0\n",
    "for i in range(len(data)):\n",
    "    kpsArr = []\n",
    "    labels = []\n",
    "    for kps in data[i]['xs'].items():\n",
    "        print\n",
    "        kpsArr.append(kps[1])\n",
    "    for label in data[i]['ys'].items():\n",
    "        labels.append(labelToNumerical(label[1]))\n",
    "    x_train.append(kpsArr)\n",
    "    y_train.append(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 481.95, 640.0, 495.3375, 613.3333333333334, 508.725, 426.6666666666667, 428.4, 266.6666666666667, 468.5625, 666.6666666666666, 415.0125, 453.3333333333333, 334.6875, 293.3333333333333, 575.6625, 853.3333333333334, 307.9125, 1146.6666666666667, 200.8125, 1306.6666666666667, 589.05, 880.0, 696.15, 960.0, 736.3125, 1120.0, 0, 0, 0, 0, 455.175, 533.3333333333334, 388.2375, 613.3333333333334]\n",
      "(497, 36)\n",
      "[   0.            0.          481.95        640.          495.3375\n",
      "  613.33333333  508.725       426.66666667  428.4         266.66666667\n",
      "  468.5625      666.66666667  415.0125      453.33333333  334.6875\n",
      "  293.33333333  575.6625      853.33333333  307.9125     1146.66666667\n",
      "  200.8125     1306.66666667  589.05        880.          696.15\n",
      "  960.          736.3125     1120.            0.            0.\n",
      "    0.            0.          455.175       533.33333333  388.2375\n",
      "  613.33333333]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "x_train = np.asarray(x_train)\n",
    "print(x_train.shape)\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "(497, 1)\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "y_train = np.asarray(y_train)\n",
    "print(y_train.shape)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat_train = to_categorical(y_train,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cat_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 397 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "397/397 [==============================] - 0s 312us/step - loss: 196.1113 - accuracy: 0.3476 - val_loss: 150.4734 - val_accuracy: 0.0100\n",
      "Epoch 2/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 156.9442 - accuracy: 0.3778 - val_loss: 100.0614 - val_accuracy: 0.0100\n",
      "Epoch 3/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 100.8081 - accuracy: 0.3426 - val_loss: 63.1371 - val_accuracy: 0.0100\n",
      "Epoch 4/100\n",
      "397/397 [==============================] - 0s 30us/step - loss: 84.6153 - accuracy: 0.2519 - val_loss: 33.1492 - val_accuracy: 0.0100\n",
      "Epoch 5/100\n",
      "397/397 [==============================] - 0s 35us/step - loss: 48.1234 - accuracy: 0.2217 - val_loss: 1.6457 - val_accuracy: 0.0100\n",
      "Epoch 6/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 24.9143 - accuracy: 0.5113 - val_loss: 1.6122 - val_accuracy: 0.0100\n",
      "Epoch 7/100\n",
      "397/397 [==============================] - 0s 30us/step - loss: 18.1968 - accuracy: 0.5819 - val_loss: 1.4627 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 6.8123 - accuracy: 0.6020 - val_loss: 1.4818 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 8.1565 - accuracy: 0.5869 - val_loss: 1.5040 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 4.9793 - accuracy: 0.5945 - val_loss: 1.5269 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "397/397 [==============================] - 0s 30us/step - loss: 5.1403 - accuracy: 0.5869 - val_loss: 1.5424 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 4.4955 - accuracy: 0.6071 - val_loss: 1.5576 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 3.8379 - accuracy: 0.5995 - val_loss: 1.5724 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "397/397 [==============================] - 0s 30us/step - loss: 3.9038 - accuracy: 0.6196 - val_loss: 1.5869 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 4.9691 - accuracy: 0.5945 - val_loss: 1.6008 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 3.7823 - accuracy: 0.5894 - val_loss: 1.6147 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 3.0177 - accuracy: 0.5995 - val_loss: 1.6284 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 1.8580 - accuracy: 0.5768 - val_loss: 1.6423 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 2.1368 - accuracy: 0.6045 - val_loss: 1.6561 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 2.1007 - accuracy: 0.6020 - val_loss: 1.6698 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 1.3431 - accuracy: 0.5894 - val_loss: 1.6834 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 1.3492 - accuracy: 0.6071 - val_loss: 1.6970 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 2.1580 - accuracy: 0.6096 - val_loss: 1.7103 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 1.3088 - accuracy: 0.6096 - val_loss: 1.7236 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "397/397 [==============================] - 0s 30us/step - loss: 1.3520 - accuracy: 0.6096 - val_loss: 1.7367 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 1.9442 - accuracy: 0.6146 - val_loss: 1.7497 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "397/397 [==============================] - 0s 30us/step - loss: 2.0229 - accuracy: 0.6045 - val_loss: 1.7625 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 1.8911 - accuracy: 0.6121 - val_loss: 1.7755 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 1.1596 - accuracy: 0.6146 - val_loss: 1.7884 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 1.8264 - accuracy: 0.6071 - val_loss: 1.8010 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "397/397 [==============================] - 0s 35us/step - loss: 1.4042 - accuracy: 0.6196 - val_loss: 1.8138 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 1.7340 - accuracy: 0.6020 - val_loss: 1.8263 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "397/397 [==============================] - 0s 30us/step - loss: 1.6629 - accuracy: 0.6096 - val_loss: 1.8387 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 1.2271 - accuracy: 0.6071 - val_loss: 1.8514 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "397/397 [==============================] - 0s 30us/step - loss: 1.1056 - accuracy: 0.6071 - val_loss: 1.8640 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "397/397 [==============================] - 0s 35us/step - loss: 1.1969 - accuracy: 0.6146 - val_loss: 1.8767 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "397/397 [==============================] - 0s 35us/step - loss: 1.4704 - accuracy: 0.6121 - val_loss: 1.8894 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "397/397 [==============================] - 0s 35us/step - loss: 1.2101 - accuracy: 0.5970 - val_loss: 1.9020 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 1.7154 - accuracy: 0.6272 - val_loss: 1.9142 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 1.3986 - accuracy: 0.6222 - val_loss: 1.9265 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "397/397 [==============================] - 0s 35us/step - loss: 1.6734 - accuracy: 0.5970 - val_loss: 1.9389 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "397/397 [==============================] - 0s 30us/step - loss: 1.5998 - accuracy: 0.6171 - val_loss: 1.9512 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 1.1454 - accuracy: 0.6121 - val_loss: 1.9632 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 1.0571 - accuracy: 0.6272 - val_loss: 1.9754 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "397/397 [==============================] - 0s 35us/step - loss: 1.2883 - accuracy: 0.6096 - val_loss: 1.9874 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 1.1155 - accuracy: 0.6171 - val_loss: 1.9994 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 1.1137 - accuracy: 0.6196 - val_loss: 2.0115 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "397/397 [==============================] - 0s 35us/step - loss: 1.2815 - accuracy: 0.6071 - val_loss: 2.0236 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 1.2603 - accuracy: 0.5970 - val_loss: 2.0356 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "397/397 [==============================] - 0s 30us/step - loss: 1.4014 - accuracy: 0.5970 - val_loss: 2.0477 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "397/397 [==============================] - 0s 35us/step - loss: 1.0729 - accuracy: 0.6297 - val_loss: 2.0596 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 1.0694 - accuracy: 0.6272 - val_loss: 2.0715 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 1.2064 - accuracy: 0.6196 - val_loss: 2.0829 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 1.0250 - accuracy: 0.6196 - val_loss: 2.0946 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "397/397 [==============================] - 0s 30us/step - loss: 1.2567 - accuracy: 0.6096 - val_loss: 2.1063 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 1.0831 - accuracy: 0.6146 - val_loss: 2.1180 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "397/397 [==============================] - 0s 30us/step - loss: 1.1536 - accuracy: 0.6121 - val_loss: 2.1298 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 1.0695 - accuracy: 0.6071 - val_loss: 2.1416 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "397/397 [==============================] - 0s 35us/step - loss: 1.0670 - accuracy: 0.6146 - val_loss: 2.1534 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 1.2256 - accuracy: 0.6247 - val_loss: 2.1649 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 1.0255 - accuracy: 0.6121 - val_loss: 2.1763 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "397/397 [==============================] - 0s 35us/step - loss: 1.2471 - accuracy: 0.6045 - val_loss: 2.1878 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "397/397 [==============================] - 0s 35us/step - loss: 0.9903 - accuracy: 0.6297 - val_loss: 2.1992 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "397/397 [==============================] - 0s 35us/step - loss: 0.9926 - accuracy: 0.6247 - val_loss: 2.2106 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 1.1065 - accuracy: 0.6196 - val_loss: 2.2218 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 0.9945 - accuracy: 0.6247 - val_loss: 2.2331 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 1.1899 - accuracy: 0.6045 - val_loss: 2.2442 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "397/397 [==============================] - 0s 35us/step - loss: 1.0611 - accuracy: 0.6222 - val_loss: 2.2555 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "397/397 [==============================] - 0s 35us/step - loss: 1.0480 - accuracy: 0.6096 - val_loss: 2.2667 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "397/397 [==============================] - 0s 35us/step - loss: 1.0092 - accuracy: 0.6272 - val_loss: 2.2778 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "397/397 [==============================] - 0s 35us/step - loss: 0.9996 - accuracy: 0.6171 - val_loss: 2.2888 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 0.9755 - accuracy: 0.6297 - val_loss: 2.2998 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 1.0436 - accuracy: 0.6222 - val_loss: 2.3109 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "397/397 [==============================] - 0s 28us/step - loss: 0.9929 - accuracy: 0.6247 - val_loss: 2.3216 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 1.0479 - accuracy: 0.6096 - val_loss: 2.3326 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "397/397 [==============================] - 0s 35us/step - loss: 0.9980 - accuracy: 0.6071 - val_loss: 2.3435 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 1.0494 - accuracy: 0.6071 - val_loss: 2.3544 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 1.0060 - accuracy: 0.6121 - val_loss: 2.3652 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 0.9836 - accuracy: 0.6196 - val_loss: 2.3759 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "397/397 [==============================] - 0s 30us/step - loss: 1.0500 - accuracy: 0.6146 - val_loss: 2.3865 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 0.9742 - accuracy: 0.6222 - val_loss: 2.3972 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "397/397 [==============================] - 0s 35us/step - loss: 0.9923 - accuracy: 0.6398 - val_loss: 2.4076 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "397/397 [==============================] - 0s 35us/step - loss: 0.9792 - accuracy: 0.6196 - val_loss: 2.4180 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "397/397 [==============================] - 0s 35us/step - loss: 0.9853 - accuracy: 0.6171 - val_loss: 2.4285 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "397/397 [==============================] - 0s 35us/step - loss: 0.9691 - accuracy: 0.6247 - val_loss: 2.4390 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "397/397 [==============================] - 0s 35us/step - loss: 1.0113 - accuracy: 0.5970 - val_loss: 2.4494 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "397/397 [==============================] - 0s 35us/step - loss: 0.9828 - accuracy: 0.6121 - val_loss: 2.4601 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "397/397 [==============================] - 0s 35us/step - loss: 0.9832 - accuracy: 0.6171 - val_loss: 2.4705 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "397/397 [==============================] - 0s 35us/step - loss: 1.0032 - accuracy: 0.6096 - val_loss: 2.4809 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "397/397 [==============================] - 0s 35us/step - loss: 0.9876 - accuracy: 0.6121 - val_loss: 2.4912 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "397/397 [==============================] - 0s 35us/step - loss: 0.9802 - accuracy: 0.6196 - val_loss: 2.5016 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 0.9613 - accuracy: 0.6247 - val_loss: 2.5120 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 0.9866 - accuracy: 0.6071 - val_loss: 2.5221 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "397/397 [==============================] - 0s 35us/step - loss: 0.9651 - accuracy: 0.6196 - val_loss: 2.5323 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "397/397 [==============================] - 0s 30us/step - loss: 0.9574 - accuracy: 0.6297 - val_loss: 2.5422 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 0.9575 - accuracy: 0.6272 - val_loss: 2.5522 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 0.9377 - accuracy: 0.6348 - val_loss: 2.5622 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "397/397 [==============================] - 0s 33us/step - loss: 0.9549 - accuracy: 0.6272 - val_loss: 2.5721 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "397/397 [==============================] - 0s 35us/step - loss: 0.9362 - accuracy: 0.6423 - val_loss: 2.5819 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "397/397 [==============================] - 0s 35us/step - loss: 0.9695 - accuracy: 0.6146 - val_loss: 2.5918 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(x_train, y_cat_train, validation_split=0.2, verbose=1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x229f8027148>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(hist.history['loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
