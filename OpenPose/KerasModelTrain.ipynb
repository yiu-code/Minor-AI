{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('OpenPoseV2.json') as f:\n",
    "  file = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = file['data']\n",
    "x_train =[]\n",
    "y_train = []\n",
    "\n",
    "def labelToNumerical(label):\n",
    "    if label == 'WarriorPoseI':\n",
    "        return 0\n",
    "    if label == 'WarriorPoseII':\n",
    "        return 1\n",
    "    if label == 'WarriorPoseIII':\n",
    "        return 2\n",
    "    if label == 'TreePose':\n",
    "        return 3\n",
    "\n",
    "i = 0\n",
    "for i in range(len(data)):\n",
    "    kpsArr = []\n",
    "    labels = []\n",
    "    for kps in data[i]['xs'].items():\n",
    "        print\n",
    "        kpsArr.append(kps[1])\n",
    "    for label in data[i]['ys'].items():\n",
    "        labels.append(labelToNumerical(label[1]))\n",
    "    x_train.append(kpsArr)\n",
    "    y_train.append(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[446.025, 116.66666666666667, 446.025, 157.5, 438.2, 169.16666666666666, 446.025, 215.83333333333334, 0, 0, 453.85, 151.66666666666666, 469.5, 93.33333333333333, 485.15, 64.16666666666667, 438.2, 221.66666666666666, 391.25, 250.83333333333334, 399.075, 320.8333333333333, 461.675, 215.83333333333334, 500.8, 256.6666666666667, 563.4, 297.5, 446.025, 116.66666666666667, 453.85, 116.66666666666667, 0, 0, 0, 0]\n",
      "(1295, 36)\n",
      "[446.025      116.66666667 446.025      157.5        438.2\n",
      " 169.16666667 446.025      215.83333333   0.           0.\n",
      " 453.85       151.66666667 469.5         93.33333333 485.15\n",
      "  64.16666667 438.2        221.66666667 391.25       250.83333333\n",
      " 399.075      320.83333333 461.675      215.83333333 500.8\n",
      " 256.66666667 563.4        297.5        446.025      116.66666667\n",
      " 453.85       116.66666667   0.           0.           0.\n",
      "   0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])\n",
    "x_train = np.asarray(x_train)\n",
    "print(x_train.shape)\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "(1295, 1)\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [3]\n",
      " [3]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "y_train = np.asarray(y_train)\n",
    "print(y_train.shape)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat_train = to_categorical(y_train,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cat_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1036 samples, validate on 259 samples\n",
      "Epoch 1/100\n",
      "1036/1036 [==============================] - 0s 116us/step - loss: 252.4121 - accuracy: 0.3764 - val_loss: 278.7564 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1036/1036 [==============================] - 0s 33us/step - loss: 69.9500 - accuracy: 0.3716 - val_loss: 60.3544 - val_accuracy: 0.1351\n",
      "Epoch 3/100\n",
      "1036/1036 [==============================] - 0s 31us/step - loss: 20.7462 - accuracy: 0.4730 - val_loss: 27.0432 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1036/1036 [==============================] - 0s 30us/step - loss: 8.5352 - accuracy: 0.5338 - val_loss: 15.5850 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1036/1036 [==============================] - 0s 30us/step - loss: 5.5214 - accuracy: 0.5241 - val_loss: 10.5485 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1036/1036 [==============================] - 0s 29us/step - loss: 4.6771 - accuracy: 0.5068 - val_loss: 8.0288 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1036/1036 [==============================] - 0s 29us/step - loss: 2.9272 - accuracy: 0.5125 - val_loss: 7.1302 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1036/1036 [==============================] - 0s 28us/step - loss: 2.8868 - accuracy: 0.5087 - val_loss: 6.6904 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "1036/1036 [==============================] - 0s 29us/step - loss: 2.0905 - accuracy: 0.5106 - val_loss: 6.0305 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1036/1036 [==============================] - 0s 29us/step - loss: 1.8398 - accuracy: 0.4990 - val_loss: 5.1183 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "1036/1036 [==============================] - 0s 28us/step - loss: 1.6504 - accuracy: 0.5010 - val_loss: 4.8927 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "1036/1036 [==============================] - 0s 29us/step - loss: 1.5142 - accuracy: 0.5029 - val_loss: 4.8414 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "1036/1036 [==============================] - 0s 28us/step - loss: 1.4895 - accuracy: 0.5048 - val_loss: 4.7830 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "1036/1036 [==============================] - 0s 29us/step - loss: 1.7003 - accuracy: 0.4990 - val_loss: 4.5572 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "1036/1036 [==============================] - 0s 29us/step - loss: 1.5852 - accuracy: 0.5029 - val_loss: 4.2969 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "1036/1036 [==============================] - 0s 28us/step - loss: 1.5058 - accuracy: 0.4981 - val_loss: 4.0468 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "1036/1036 [==============================] - 0s 32us/step - loss: 1.4270 - accuracy: 0.4981 - val_loss: 4.0036 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "1036/1036 [==============================] - 0s 34us/step - loss: 1.3158 - accuracy: 0.4981 - val_loss: 3.9873 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "1036/1036 [==============================] - 0s 29us/step - loss: 1.2937 - accuracy: 0.4961 - val_loss: 3.9872 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "1036/1036 [==============================] - 0s 32us/step - loss: 1.4351 - accuracy: 0.4942 - val_loss: 3.8978 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "1036/1036 [==============================] - 0s 34us/step - loss: 1.3944 - accuracy: 0.4961 - val_loss: 3.8726 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "1036/1036 [==============================] - 0s 32us/step - loss: 1.2810 - accuracy: 0.4990 - val_loss: 3.8647 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "1036/1036 [==============================] - 0s 28us/step - loss: 1.3452 - accuracy: 0.4952 - val_loss: 3.8489 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "1036/1036 [==============================] - 0s 29us/step - loss: 1.3015 - accuracy: 0.5000 - val_loss: 3.8486 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "1036/1036 [==============================] - 0s 30us/step - loss: 1.4529 - accuracy: 0.5010 - val_loss: 3.8538 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "1036/1036 [==============================] - 0s 29us/step - loss: 1.2249 - accuracy: 0.4981 - val_loss: 3.8596 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "1036/1036 [==============================] - 0s 28us/step - loss: 1.2567 - accuracy: 0.5000 - val_loss: 3.8690 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "1036/1036 [==============================] - 0s 28us/step - loss: 1.2004 - accuracy: 0.4990 - val_loss: 3.8515 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "1036/1036 [==============================] - 0s 29us/step - loss: 1.2514 - accuracy: 0.4961 - val_loss: 3.8138 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "1036/1036 [==============================] - 0s 30us/step - loss: 1.2641 - accuracy: 0.4981 - val_loss: 3.8280 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "1036/1036 [==============================] - 0s 29us/step - loss: 1.1915 - accuracy: 0.4923 - val_loss: 3.8507 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "1036/1036 [==============================] - 0s 29us/step - loss: 1.1974 - accuracy: 0.4981 - val_loss: 3.8740 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "1036/1036 [==============================] - 0s 28us/step - loss: 1.1779 - accuracy: 0.4981 - val_loss: 3.8994 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "1036/1036 [==============================] - 0s 30us/step - loss: 1.2175 - accuracy: 0.4961 - val_loss: 3.9213 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "1036/1036 [==============================] - 0s 30us/step - loss: 1.2171 - accuracy: 0.4981 - val_loss: 3.8941 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "1036/1036 [==============================] - 0s 29us/step - loss: 1.1831 - accuracy: 0.4981 - val_loss: 3.9141 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "1036/1036 [==============================] - 0s 29us/step - loss: 1.1556 - accuracy: 0.4923 - val_loss: 3.9275 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "1036/1036 [==============================] - 0s 30us/step - loss: 1.1801 - accuracy: 0.4952 - val_loss: 3.9423 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "1036/1036 [==============================] - 0s 36us/step - loss: 1.2035 - accuracy: 0.4971 - val_loss: 3.9646 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "1036/1036 [==============================] - 0s 29us/step - loss: 1.1643 - accuracy: 0.4971 - val_loss: 3.9763 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "1036/1036 [==============================] - 0s 28us/step - loss: 1.1680 - accuracy: 0.4971 - val_loss: 3.9938 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "1036/1036 [==============================] - 0s 29us/step - loss: 1.1769 - accuracy: 0.5029 - val_loss: 4.0134 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "1036/1036 [==============================] - 0s 28us/step - loss: 1.2942 - accuracy: 0.4923 - val_loss: 4.0327 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "1036/1036 [==============================] - 0s 32us/step - loss: 1.1737 - accuracy: 0.5039 - val_loss: 4.0344 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "1036/1036 [==============================] - 0s 29us/step - loss: 1.1546 - accuracy: 0.4981 - val_loss: 4.0527 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "1036/1036 [==============================] - 0s 31us/step - loss: 1.1423 - accuracy: 0.5058 - val_loss: 4.0707 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "1036/1036 [==============================] - 0s 32us/step - loss: 1.1296 - accuracy: 0.5019 - val_loss: 4.0908 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "1036/1036 [==============================] - 0s 31us/step - loss: 1.1508 - accuracy: 0.4961 - val_loss: 4.0983 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "1036/1036 [==============================] - 0s 30us/step - loss: 1.1440 - accuracy: 0.5019 - val_loss: 4.1126 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "1036/1036 [==============================] - 0s 29us/step - loss: 1.1477 - accuracy: 0.4990 - val_loss: 4.1363 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "1036/1036 [==============================] - 0s 30us/step - loss: 1.1343 - accuracy: 0.4971 - val_loss: 4.1495 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "1036/1036 [==============================] - 0s 30us/step - loss: 1.2417 - accuracy: 0.4981 - val_loss: 4.1525 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "1036/1036 [==============================] - 0s 29us/step - loss: 1.1457 - accuracy: 0.4981 - val_loss: 4.1644 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "1036/1036 [==============================] - 0s 30us/step - loss: 1.2509 - accuracy: 0.4952 - val_loss: 4.1766 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "1036/1036 [==============================] - 0s 31us/step - loss: 1.2265 - accuracy: 0.4981 - val_loss: 4.1824 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "1036/1036 [==============================] - 0s 30us/step - loss: 1.1621 - accuracy: 0.4932 - val_loss: 4.1903 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "1036/1036 [==============================] - 0s 30us/step - loss: 1.1583 - accuracy: 0.4942 - val_loss: 4.1976 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "1036/1036 [==============================] - 0s 31us/step - loss: 1.1361 - accuracy: 0.5000 - val_loss: 4.2124 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "1036/1036 [==============================] - 0s 30us/step - loss: 1.1522 - accuracy: 0.4932 - val_loss: 4.2277 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "1036/1036 [==============================] - 0s 30us/step - loss: 1.1398 - accuracy: 0.4942 - val_loss: 4.2435 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "1036/1036 [==============================] - 0s 29us/step - loss: 1.1265 - accuracy: 0.4981 - val_loss: 4.2581 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "1036/1036 [==============================] - 0s 30us/step - loss: 1.2163 - accuracy: 0.4981 - val_loss: 4.2732 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "1036/1036 [==============================] - 0s 30us/step - loss: 1.1290 - accuracy: 0.5000 - val_loss: 4.2877 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "1036/1036 [==============================] - 0s 29us/step - loss: 1.1330 - accuracy: 0.4971 - val_loss: 4.3007 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "1036/1036 [==============================] - 0s 29us/step - loss: 1.1306 - accuracy: 0.4981 - val_loss: 4.3196 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "1036/1036 [==============================] - 0s 27us/step - loss: 1.1234 - accuracy: 0.5010 - val_loss: 4.3268 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "1036/1036 [==============================] - 0s 30us/step - loss: 1.2117 - accuracy: 0.4981 - val_loss: 4.3340 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "1036/1036 [==============================] - 0s 30us/step - loss: 1.2068 - accuracy: 0.4961 - val_loss: 4.3534 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "1036/1036 [==============================] - 0s 29us/step - loss: 1.1306 - accuracy: 0.4971 - val_loss: 4.3327 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "1036/1036 [==============================] - 0s 27us/step - loss: 1.1272 - accuracy: 0.4971 - val_loss: 4.3570 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "1036/1036 [==============================] - 0s 29us/step - loss: 1.1264 - accuracy: 0.4961 - val_loss: 4.3692 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "1036/1036 [==============================] - 0s 29us/step - loss: 1.1255 - accuracy: 0.4971 - val_loss: 4.3808 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "1036/1036 [==============================] - 0s 29us/step - loss: 1.1202 - accuracy: 0.5000 - val_loss: 4.3953 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "1036/1036 [==============================] - 0s 28us/step - loss: 1.1280 - accuracy: 0.4952 - val_loss: 4.4198 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "1036/1036 [==============================] - 0s 30us/step - loss: 1.1231 - accuracy: 0.4981 - val_loss: 4.4324 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "1036/1036 [==============================] - 0s 29us/step - loss: 1.1181 - accuracy: 0.5010 - val_loss: 4.4649 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "1036/1036 [==============================] - 0s 28us/step - loss: 1.1185 - accuracy: 0.5010 - val_loss: 4.4827 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "1036/1036 [==============================] - 0s 31us/step - loss: 1.1325 - accuracy: 0.5010 - val_loss: 4.4460 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "1036/1036 [==============================] - 0s 30us/step - loss: 1.1254 - accuracy: 0.4961 - val_loss: 4.4248 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "1036/1036 [==============================] - 0s 31us/step - loss: 1.1189 - accuracy: 0.5000 - val_loss: 4.4342 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "1036/1036 [==============================] - 0s 30us/step - loss: 1.1214 - accuracy: 0.4981 - val_loss: 4.4462 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "1036/1036 [==============================] - 0s 30us/step - loss: 1.1256 - accuracy: 0.4952 - val_loss: 4.4546 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "1036/1036 [==============================] - 0s 29us/step - loss: 1.1276 - accuracy: 0.4942 - val_loss: 4.4653 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "1036/1036 [==============================] - 0s 30us/step - loss: 1.1239 - accuracy: 0.4961 - val_loss: 4.4865 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "1036/1036 [==============================] - 0s 31us/step - loss: 1.1217 - accuracy: 0.4971 - val_loss: 4.5143 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "1036/1036 [==============================] - 0s 28us/step - loss: 1.1243 - accuracy: 0.4961 - val_loss: 4.5270 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "1036/1036 [==============================] - 0s 27us/step - loss: 1.1191 - accuracy: 0.4990 - val_loss: 4.5379 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "1036/1036 [==============================] - 0s 31us/step - loss: 1.1182 - accuracy: 0.5000 - val_loss: 4.5483 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "1036/1036 [==============================] - 0s 28us/step - loss: 1.1233 - accuracy: 0.4961 - val_loss: 4.5604 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "1036/1036 [==============================] - 0s 31us/step - loss: 1.1197 - accuracy: 0.4990 - val_loss: 4.5715 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "1036/1036 [==============================] - 0s 33us/step - loss: 1.1159 - accuracy: 0.5019 - val_loss: 4.5718 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "1036/1036 [==============================] - 0s 31us/step - loss: 1.1089 - accuracy: 0.5058 - val_loss: 4.5707 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "1036/1036 [==============================] - 0s 29us/step - loss: 1.1890 - accuracy: 0.4990 - val_loss: 4.5804 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "1036/1036 [==============================] - 0s 30us/step - loss: 1.1206 - accuracy: 0.4981 - val_loss: 4.6120 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "1036/1036 [==============================] - 0s 28us/step - loss: 1.1870 - accuracy: 0.4961 - val_loss: 4.5954 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "1036/1036 [==============================] - 0s 30us/step - loss: 1.1226 - accuracy: 0.4961 - val_loss: 4.5997 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "1036/1036 [==============================] - 0s 28us/step - loss: 1.1206 - accuracy: 0.4981 - val_loss: 4.6135 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "1036/1036 [==============================] - 0s 27us/step - loss: 1.1190 - accuracy: 0.4990 - val_loss: 4.6208 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "1036/1036 [==============================] - 0s 28us/step - loss: 1.1260 - accuracy: 0.4942 - val_loss: 4.6318 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "1036/1036 [==============================] - 0s 28us/step - loss: 1.1180 - accuracy: 0.4990 - val_loss: 4.6364 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(x_train, y_cat_train, validation_split=0.2, verbose=1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a3e9a31608>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(hist.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('OpenPose_Keras.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
