{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from pycocotools.coco import COCO\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "from imgaug.augmentables import Keypoint, KeypointsOnImage\n",
    "\n",
    "class Process(object):\n",
    "    numKeypoint = 17\n",
    "    keypointsName = ['nose', 'left_eye', 'right_eye', 'left_ear', 'right_ear', \n",
    "                    'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow', \n",
    "                    'left_wrist', 'right_wrist', 'left_hip', 'right_hip', 'left_knee', \n",
    "                    'right_knee', 'left_ankle', 'right_ankle']\n",
    "\n",
    "    skeleton = [[15, 13], [13, 11], [16, 14], \n",
    "                [14, 12], [11, 12], [5, 11], \n",
    "                [6, 12], [5, 6], [5, 7], [6, 8], \n",
    "                [7, 9], [8, 10], [1, 2], [0, 1], \n",
    "                [0, 2], [1, 3], [2, 4], [3, 5], [4, 6]]\n",
    "    \n",
    "    trainAnnoPath = 'COCO/annotations/person_keypoints_train2017.json'\n",
    "    valAnnoPath = 'COCO/annotations/person_keypoints_val2017.json'\n",
    "    \n",
    "    def loadData(self, setType):\n",
    "        if setType == 'train':\n",
    "            coco = COCO(self.trainAnnoPath)\n",
    "        elif setType == 'val':\n",
    "            coco = COCO(self.valAnnoPath)\n",
    "            \n",
    "        Data = []\n",
    "        for aid in coco.anns.keys():\n",
    "            ann =  coco.anns[aid]\n",
    "            keypoints = ann['keypoints']\n",
    "            \n",
    "            if  keypoints.count(0) == 0: \n",
    "                imageName = 'COCO/' + setType + '2017/' + coco.imgs[ann['image_id']]['file_name']\n",
    "\n",
    "                if (ann['image_id'] not in coco.imgs) or ann['iscrowd'] or (np.sum(keypoints[2::3]) == 0) or (ann['num_keypoints'] == 0):\n",
    "                    continue\n",
    "\n",
    "                data = dict(image_id = ann['image_id'], imgpath = imageName, bbox=ann['bbox'], keypoints=keypoints)\n",
    "                Data.append(data)\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "        return Data\n",
    "    \n",
    "    def imagesToNdarry(self, data): \n",
    "        imgPath = []\n",
    "        i = 0\n",
    "        for i in range(len(data)):\n",
    "            img = cv2.imread(data[i]['imgpath'])\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            imgPath.append(img)\n",
    "            \n",
    "        return np.array(imgPath)\n",
    "    \n",
    "    def splitKeypoints(self, data):\n",
    "        kpsList = []\n",
    "        visibiltyList = []\n",
    "        for ann in data:\n",
    "            keypoints = np.array(ann['keypoints']).astype(int)\n",
    "            keypoints =  keypoints.reshape(17,3)\n",
    "            keypoints = self.reshapeKeypoints(keypoints)\n",
    "            kpsList.append(keypoints['kps'])\n",
    "            visibiltyList.append(keypoints['visibility'])\n",
    "\n",
    "        return kpsList, visibiltyList\n",
    "    \n",
    "    def reshapeKeypoints(self, keypoints):\n",
    "        keypoint = []\n",
    "        visibility = []\n",
    "\n",
    "        for kps in keypoints: \n",
    "            x,y,v = kps \n",
    "            keypoint.append(Keypoint(x,y))\n",
    "            visibility.append(v)\n",
    "            \n",
    "        res = dict()\n",
    "        res['kps'] = keypoint; res['visibility'] = visibility\n",
    "        return res\n",
    "    \n",
    "#     def augmentKeypoints(self, keypoints, shape):\n",
    "#         augKpsList = []\n",
    "#         for kps in keypoints:\n",
    "#             augKps = self.augmentation.augment_keypoints(KeypointsOnImage(kps, shape))\n",
    "#             augKpsList.append(augKps)\n",
    "#         return augKpsList\n",
    "\n",
    "    def augmentationOnAll(self, images, kps):\n",
    "        seq = iaa.Sequential([\n",
    "            iaa.Resize(112),            \n",
    "        ])\n",
    "\n",
    "        imgAugList = []\n",
    "        kpsAugList = []\n",
    "        \n",
    "        i = 0 \n",
    "        for i in range(len(images)):\n",
    "            imgAug, kpsAug = seq(image=images[i], keypoints=KeypointsOnImage(kps[i],shape=images[i].shape))\n",
    "            imgAugList.append(imgAug)\n",
    "            kpsAugList.append(kpsAug)\n",
    "            \n",
    "        return np.array(imgAugList), kpsAugList\n",
    "\n",
    "    def mergeKpsVisibility(self, augKps, visibility, kpShape, MergeShape):\n",
    "        kpsList = [] \n",
    "        i = 0\n",
    "        for i in range(len(augKps)):\n",
    "            for keypoint in augKps[i]:\n",
    "                x,y = keypoint.x, keypoint.y\n",
    "                kpsList.append(x)\n",
    "                kpsList.append(y)\n",
    "        kpsList = np.array(kpsList).reshape(kpShape)\n",
    "        merge = np.dstack((kpsList, visibility))\n",
    "        merge = merge.reshape(MergeShape)\n",
    "        return merge\n",
    "\n",
    "processing = Process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetchedData = processing.loadData('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(fetchedData))\n",
    "# batch1 = fetchedData[:2500]\n",
    "# there are in total of 18 batches but our pc can't handle it. (5551 * 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = processing.imagesToNdarry(batch1)\n",
    "# allKeypoints, allVisibility = processing.getAllKeypoints(batch1)\n",
    "# print(len(allKeypoints), len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, kps = processing.augmentationOnAll(images, allKeypoints)\n",
    "# y_train = processing.mergeKpsVisibility(kps, allVisibility, (2500, 17,2), (2500, 51))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #check if x_train is 4dArray\n",
    "# print(x_train.shape)\n",
    "\n",
    "# #check resized keypoints value \n",
    "# print(kps[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
